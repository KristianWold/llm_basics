{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04010a08",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa3d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tokenizer import TokenizerBPE\n",
    "from data_handling import normalize_to_ascii, clean_text\n",
    "from utils import saver\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import os\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "# disable gpu for testing purposes\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afb751",
   "metadata": {},
   "source": [
    "## Standford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c88ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../corpus/train-v2.0.json', 'r', encoding='utf-8') as f:\n",
    "    squad = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9b6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = []\n",
    "\n",
    "num_articles = len(squad['data'])\n",
    "question_grouped = []\n",
    "answer_grouped = []\n",
    "\n",
    "for article in squad['data']:\n",
    "    title = article['title']\n",
    "    for paragraph in article['paragraphs']:\n",
    "        question_grouped.append([])\n",
    "        answer_grouped.append([])\n",
    "        context_list.append(clean_text(normalize_to_ascii(paragraph['context'])))\n",
    "        for qa in paragraph['qas']:\n",
    "            if not qa['is_impossible']:\n",
    "                \n",
    "                question = qa['question']\n",
    "                answer = qa['answers']\n",
    "\n",
    "                question_grouped[-1].append(clean_text(normalize_to_ascii(question)))\n",
    "                answer_grouped[-1].append(clean_text(normalize_to_ascii(answer[0]['text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce808c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver(\"../corpus/squad_raw\", [context_list, question_grouped, answer_grouped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6811bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fused_sqa(story_list, question_grouped_list, answer_grouped_list):\n",
    "    q =\"<q>\"\n",
    "    a = \"<a>\"\n",
    "    sos = \"<s>\"\n",
    "    eos = \"</s>\"\n",
    "\n",
    "    rcw = re.compile(r\"\\s+\")\n",
    "\n",
    "    corpus_list = []\n",
    "    for story, question_list, answer_list in tqdm(list(zip(story_list, question_grouped_list, answer_grouped_list))):\n",
    "        story = story.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        story = rcw.sub(\" \", story).strip()\n",
    "        sqa = [sos, normalize_to_ascii(story).lower()]\n",
    "        for question, answer in zip(question_list, answer_list):\n",
    "            question = question.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            question = rcw.sub(\" \", question).strip()\n",
    "            answer = answer.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            answer = rcw.sub(\" \", answer).strip()\n",
    "            sqa.append(q)\n",
    "            sqa.append(normalize_to_ascii(question).lower())\n",
    "            sqa.append(a)\n",
    "            sqa.append(normalize_to_ascii(answer).lower())\n",
    "        sqa.append(eos)\n",
    "        corpus_list.append(\"\".join(sqa))\n",
    "        \n",
    "    return corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f59b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a2d61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_corpus(corpus, max_length, tokenizer):\n",
    "    pad_token = tokenizer.token_to_idx[\"<pad>\"]\n",
    "    padded_corpus = []\n",
    "    for line in tqdm(corpus):\n",
    "        if line.shape[1] < max_length:\n",
    "            padding = tf.repeat(tf.constant([[pad_token]]), max_length - line.shape[1], axis=1)\n",
    "            padded_line = tf.concat([line, padding], axis=1)\n",
    "        else:\n",
    "            padded_line = line[:, :max_length]\n",
    "        padded_corpus.append(padded_line)\n",
    "    return tf.concat(padded_corpus, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e228e14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031d4d881bda46dbb6d4ce4213370f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19035 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_encoded = pkl.load(open('../corpus/corpus_clean/corpus_squad_sqa_24k', 'rb'))\n",
    "corpus_padded = pad_corpus(corpus_encoded, 768, tokenizer)\n",
    "pkl.dump(corpus_padded, open('../corpus/corpus_clean/corpus_squad_sqa_24k_padded', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f20b",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
