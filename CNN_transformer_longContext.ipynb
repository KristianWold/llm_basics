{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04010a08",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa3d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA toolkit version PyTorch was built with: 12.8\n",
      "cuDNN version: 90701\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "#from src.tokenizer import TokenizerBPE, fuse_tokenized_corpus, chunk_corpus\n",
    "\n",
    "#import matplotlib as plt\n",
    "import os\n",
    "import time\n",
    "import torch as torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from src.transformer import Transformer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA toolkit version PyTorch was built with:\", torch.version.cuda)  \n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version()) \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e38fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = pkl.load(open('corpus/corpus_CNN_24k_whitespace_train_numpy', 'rb'))\n",
    "corpus_train = torch.tensor(corpus_train, dtype=torch.int64)\n",
    "data_train = TensorDataset(corpus_train)\n",
    "\n",
    "\n",
    "corpus_test = pkl.load(open('corpus/corpus_CNN_24k_whitespace_test_numpy', 'rb'))\n",
    "corpus_test = torch.tensor(corpus_test, dtype=torch.int64)\n",
    "data_test = TensorDataset(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568eb993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159109120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train.shape[0]*corpus_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c15e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(\n",
    "    data_train,\n",
    "    batch_size=3,\n",
    "    shuffle=True,       # shuffle every epoch\n",
    "    drop_last=False     # whether to drop the tail batch if smaller than batch_size\n",
    ")\n",
    "\n",
    "loader_test = DataLoader(\n",
    "    data_test,\n",
    "    batch_size=8,\n",
    "    shuffle=True,      \n",
    "    drop_last=False\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f2ab524",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64*14\n",
    "ff_dim = 4*embed_dim\n",
    "heads = 14\n",
    "tf_blocks = 14\n",
    "\n",
    "transformer = Transformer(\n",
    "    embed_dim=embed_dim,\n",
    "    ff_dim=ff_dim,\n",
    "    heads=heads,\n",
    "    tf_blocks=tf_blocks,\n",
    "    vocab_size=24072,\n",
    "    max_seq_len=1024,\n",
    "    dropout=0.1,\n",
    "    start_token_id=24070,\n",
    "    use_weight_tying=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f65b240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157496072\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for parameter in transformer.parameters():\n",
    "    temp = 1\n",
    "    for dim in parameter.shape:\n",
    "        temp *= dim\n",
    "\n",
    "    num_params += temp\n",
    "\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffd2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer = pkl.load(open(\"corpus/model_large.model\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0a56ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_steps = 40\n",
    "\n",
    "@torch.compile\n",
    "def forward_and_loss(model, batch, criterion):\n",
    "    model.train()\n",
    "    #batch is a tensor of shape [batch, seq]\n",
    "    src, tgt = batch[:, :-1].to(device), batch[:, 1:].to(device)\n",
    "    logits = model(src)\n",
    "    return criterion(logits.reshape(-1, logits.size(-1)), tgt.reshape(-1))\n",
    "\n",
    "\n",
    "def train_step(model, batch, criterion, optimizer, scaler, scheduler, i):\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "        loss = forward_and_loss(model, batch, criterion)\n",
    "\n",
    "    scaler.scale(loss/accum_steps).backward()\n",
    "\n",
    "    if (i+1)%accum_steps == 0:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ddaab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(transformer.named_parameters())\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight'] # Parameters to exclude from weight decay\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.01}, # Apply weight decay to these parameters\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0} # No weight decay for these parameters\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d5ead6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "loss_train = []\n",
    "\n",
    "num_epochs      = 1\n",
    "steps_per_epoch = len(loader_train)\n",
    "total_steps     = num_epochs * steps_per_epoch\n",
    "warmup_steps    = 100\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return float(step) / float(max(1, warmup_steps))\n",
    "    return 1.0\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d4661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204d67861a2845b2bb89818e54df595c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/51794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 39, Loss: 10.5428, LR: 5.000000000000001e-07\n",
      "Step 79, Loss: 10.5535, LR: 1.0000000000000002e-06\n",
      "Step 119, Loss: 10.5162, LR: 1.5e-06\n",
      "Step 159, Loss: 10.4400, LR: 2.0000000000000003e-06\n",
      "Step 199, Loss: 10.3382, LR: 2.5e-06\n",
      "Step 239, Loss: 10.1983, LR: 3e-06\n",
      "Step 279, Loss: 10.0502, LR: 3.5000000000000004e-06\n",
      "Step 319, Loss: 9.8515, LR: 4.000000000000001e-06\n",
      "Step 359, Loss: 9.6711, LR: 4.5e-06\n",
      "Step 399, Loss: 9.4906, LR: 5e-06\n",
      "Step 439, Loss: 9.3000, LR: 5.500000000000001e-06\n",
      "Step 479, Loss: 9.1879, LR: 6e-06\n",
      "Step 519, Loss: 9.1196, LR: 6.5000000000000004e-06\n",
      "Step 559, Loss: 9.0372, LR: 7.000000000000001e-06\n",
      "Step 599, Loss: 8.8906, LR: 7.5e-06\n",
      "Step 639, Loss: 8.7289, LR: 8.000000000000001e-06\n",
      "Step 679, Loss: 8.7236, LR: 8.500000000000002e-06\n",
      "Step 719, Loss: 8.6652, LR: 9e-06\n",
      "Step 759, Loss: 8.6429, LR: 9.5e-06\n",
      "Step 799, Loss: 8.5536, LR: 1e-05\n",
      "Step 839, Loss: 8.4744, LR: 1.05e-05\n",
      "Step 879, Loss: 8.4199, LR: 1.1000000000000001e-05\n",
      "Step 919, Loss: 8.3764, LR: 1.1500000000000002e-05\n",
      "Step 959, Loss: 8.2737, LR: 1.2e-05\n",
      "Step 999, Loss: 8.2313, LR: 1.25e-05\n",
      "Step 1039, Loss: 8.1548, LR: 1.3000000000000001e-05\n",
      "Step 1079, Loss: 8.1064, LR: 1.3500000000000001e-05\n",
      "Step 1119, Loss: 8.0788, LR: 1.4000000000000001e-05\n",
      "Step 1159, Loss: 8.0124, LR: 1.45e-05\n",
      "Step 1199, Loss: 7.9359, LR: 1.5e-05\n",
      "Step 1239, Loss: 7.8921, LR: 1.55e-05\n",
      "Step 1279, Loss: 7.8480, LR: 1.6000000000000003e-05\n",
      "Step 1319, Loss: 7.7811, LR: 1.65e-05\n",
      "Step 1359, Loss: 7.7242, LR: 1.7000000000000003e-05\n",
      "Step 1399, Loss: 7.7059, LR: 1.75e-05\n",
      "Step 1439, Loss: 7.6372, LR: 1.8e-05\n",
      "Step 1479, Loss: 7.5932, LR: 1.85e-05\n",
      "Step 1519, Loss: 7.5753, LR: 1.9e-05\n",
      "Step 1559, Loss: 7.5298, LR: 1.9500000000000003e-05\n",
      "Step 1599, Loss: 7.5245, LR: 2e-05\n",
      "Step 1639, Loss: 7.4336, LR: 2.05e-05\n",
      "Step 1679, Loss: 7.4072, LR: 2.1e-05\n",
      "Step 1719, Loss: 7.3930, LR: 2.15e-05\n",
      "Step 1759, Loss: 7.3519, LR: 2.2000000000000003e-05\n",
      "Step 1799, Loss: 7.3666, LR: 2.25e-05\n",
      "Step 1839, Loss: 7.3457, LR: 2.3000000000000003e-05\n",
      "Step 1879, Loss: 7.2781, LR: 2.35e-05\n",
      "Step 1919, Loss: 7.3068, LR: 2.4e-05\n",
      "Step 1959, Loss: 7.3153, LR: 2.45e-05\n",
      "Step 1999, Loss: 7.2944, LR: 2.5e-05\n",
      "Step 2039, Loss: 7.2793, LR: 2.5500000000000003e-05\n",
      "Step 2079, Loss: 7.2640, LR: 2.6000000000000002e-05\n",
      "Step 2119, Loss: 7.2415, LR: 2.6500000000000004e-05\n",
      "Step 2159, Loss: 7.2640, LR: 2.7000000000000002e-05\n",
      "Step 2199, Loss: 7.2807, LR: 2.7500000000000004e-05\n",
      "Step 2239, Loss: 7.2874, LR: 2.8000000000000003e-05\n",
      "Step 2279, Loss: 7.2676, LR: 2.8499999999999998e-05\n",
      "Step 2319, Loss: 7.2412, LR: 2.9e-05\n",
      "Step 2359, Loss: 7.2541, LR: 2.95e-05\n",
      "Step 2399, Loss: 7.2718, LR: 3e-05\n",
      "Step 2439, Loss: 7.2405, LR: 3.05e-05\n",
      "Step 2479, Loss: 7.2608, LR: 3.1e-05\n",
      "Step 2519, Loss: 7.2283, LR: 3.15e-05\n",
      "Step 2559, Loss: 7.2306, LR: 3.2000000000000005e-05\n",
      "Step 2599, Loss: 7.2523, LR: 3.2500000000000004e-05\n",
      "Step 2639, Loss: 7.2521, LR: 3.3e-05\n",
      "Step 2679, Loss: 7.2142, LR: 3.35e-05\n",
      "Step 2719, Loss: 7.2223, LR: 3.4000000000000007e-05\n",
      "Step 2759, Loss: 7.2226, LR: 3.45e-05\n",
      "Step 2799, Loss: 7.2370, LR: 3.5e-05\n",
      "Step 2839, Loss: 7.2177, LR: 3.55e-05\n",
      "Step 2879, Loss: 7.2094, LR: 3.6e-05\n",
      "Step 2919, Loss: 7.2062, LR: 3.65e-05\n",
      "Step 2959, Loss: 7.2248, LR: 3.7e-05\n",
      "Step 2999, Loss: 7.2352, LR: 3.7500000000000003e-05\n",
      "Step 3039, Loss: 7.2031, LR: 3.8e-05\n",
      "Step 3079, Loss: 7.2420, LR: 3.85e-05\n",
      "Step 3119, Loss: 7.2108, LR: 3.9000000000000006e-05\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "for e in range(4):\n",
    "    loss_temp = 0\n",
    "    for i, (batch,) in tqdm(enumerate(loader_train), total=len(loader_train), desc=\"Training\"):\n",
    "        \n",
    "            batch = batch.to(device)\n",
    "            loss = train_step(transformer, batch, criterion, optimizer, scaler, scheduler, i)\n",
    "            loss_temp += loss\n",
    "            if (i+1)%accum_steps == 0:\n",
    "                lr = scheduler.get_last_lr()[0]\n",
    "                print(f\"Step {i}, Loss: {loss_temp/accum_steps:.4f}, LR: {lr}\")\n",
    "                loss_train.append(loss_temp/accum_steps)\n",
    "                loss_temp = 0\n",
    "\n",
    "            if (i+1)%1000 == 0:\n",
    "                 pkl.dump(transformer, open(f\"corpus/model_larger.model\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor([[24070]], dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f599efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa02320b40248abb419e3744a20ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='20em', width='80ch'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.69 GiB of which 72.75 MiB is free. Including non-PyTorch memory, this process has 14.95 GiB memory in use. Of the allocated memory 13.84 GiB is allocated by PyTorch, and 835.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#torch.random.torch.manual_seed(42) \u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1024\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     logits = transformer(tokens)[\u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m:]\n\u001b[32m     23\u001b[39m     topk_vals, _    = torch.topk(logits, k=k)\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m#print(topk_vals)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/slarn_chatbot/src/transformer.py:172\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.block_list:\n\u001b[32m    170\u001b[39m     x = block(x, tokens)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m x = \u001b[38;5;28mself\u001b[39m.unembed(x)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/slarn_chatbot/src/transformer.py:195\u001b[39m, in \u001b[36mTransformer.unembed\u001b[39m\u001b[34m(self, x_embeds)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munembed\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_embeds):\n\u001b[32m    193\u001b[39m     w_embed = torch.transpose(\u001b[38;5;28mself\u001b[39m.word_embed.weight, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [embed_dim, vocab_size]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     logits = x_embeds @ w_embed + \u001b[38;5;28mself\u001b[39m.unembed_b\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.69 GiB of which 72.75 MiB is free. Including non-PyTorch memory, this process has 14.95 GiB memory in use. Of the allocated memory 13.84 GiB is allocated by PyTorch, and 835.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=80)\n",
    "\n",
    "# create a read-only text area\n",
    "ta = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    layout=widgets.Layout(width='80ch', height='20em'),\n",
    "    disabled=True\n",
    ")\n",
    "display(ta)\n",
    "\n",
    "\n",
    "T = 1\n",
    "k = 50\n",
    "\n",
    "#torch.random.torch.manual_seed(42) \n",
    "\n",
    "for i in range(1024):\n",
    "    logits = transformer(tokens)[0, -1:]\n",
    "    topk_vals, _    = torch.topk(logits, k=k)\n",
    "    #print(topk_vals)\n",
    "    kth_value       = topk_vals[:,-1]\n",
    "\n",
    "    logits = torch.where(logits >= kth_value, logits, -torch.inf)\n",
    "    dist = Categorical(logits=logits/T)\n",
    "    idx = dist.sample()\n",
    "    tokens = torch.cat([tokens, idx.reshape(1,1)], dim=1)\n",
    "    #print(tokens.shape)\n",
    "    text = \"\"\n",
    "    for i in tokens[0]:\n",
    "        s = table[int(i)]\n",
    "        text = text + s\n",
    "\n",
    "    ta.value = wrapper.fill(text.replace(\"\\n\", \" \"))  # this updates in-place\n",
    "\n",
    "    if idx[0] == 24071:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43004de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " york and minnesota will be able to see him in action at 8 p.m. et august 26 on nbc, he's not making yet another comeback to the nfl. favre was on the field in grant park in downtown chicago recently with other nfl greats such as jerry rice, michael irvin, deion sanders, marcus allen and barry sanders, playing in the annual ea sports \"madden\" pigskin pro am flag football game. favre said he was happy to be back on the gridiron in organized play. \"it's kind of exciting,\" favre said. \"obviously, it's different. some of these guys i've played against and had some battles (with) over the years, but it's always nice to regroup and swap some old stories. it's always fun to play football.\" before the high-scoring affair, which included video game-style gold balls for 12-point scores and special bonuses for touchdowns thrown in certain spots in the end zone, the 11-time pro bowler wasn't promising a return to his glory days. \"i wouldn't expect too much, but we've got a lot of pride. no one's an athlete like deion (sanders); he's in a class by himself. the rest of us are just trying to show we still have a little bit of skills,\" he said. favre was gunslinging against veteran quarterback donovan mcnabb, who's not ready for retirement yet. the annual event, which also featured celebrities such as josh henderson (\"dallas\"), terry crews (\"the expendables 2\"), jesse williams (\"the cabin in the woods\") and singer nick jonas, helps drum up awareness for what gamers believe is the true start of the new nfl season -- the launch of ea sports \"madden nfl 13\" on august 28. \"i hope ea doesn't judge us off of today,\" favre said jokingly. \"the kids i work with back at the high school back home, they were giving me a hard time. they said i'm real slow on madden. i'm hoping to change that today.\" favre played video games back in the day such as pong and pac-man, but he says he's seen gaming come a long way since then. and he believes video games such as \"madden\" can help aspiring quarterbacks. \"i think it's beneficial,\" favre said. \"i also think that kids should get out and play, actually get out and do some physical stuff. i think madden does teach them a lot about the sport. the fan base that video games have reached is amazing. the advancements that they've made are just unbelievable. i think in a lot of ways it's good, as long as the kids will get out and participate in some of the things that they're playing (onscreen).\" favre was on the cover of \"madden nfl 09\" back in 2008, which marked the 20th anniversary of the bestselling game franchise. favre was originally seen in his green bay packers uniform, but electronic arts changed subsequent cover art to reflect his new york jets uniform after he came out of retirement to play again. \"i wasn't jinxed (being on the cover); i wouldn't say that,\" said favre, referring to the \"madden curse\" that has seen more than its fair share of cover athletes suffer injuries or other mishaps the season after they appear. \"i consider it a huge honor.\" detroit lions wide receiver calvin johnson graces the cover of the new \"madden nfl 13.\" electronic arts says it has completely overhauled the game, making the most changes to the franchise in its history. one of the additions is a new online mode that allows players to take former greats all the way to the hall of fame. when asked what it's like to remain in the madden franchise after retirement, favre replied, \"it's nice to know i'm alive and kicking, let's just put it that way.\" another new feature that armchair quarterbacks will be happy with is that the new madden game allows players to lead the receivers -- just like favre did during his career. when it comes to technology and video games, favre has no idea what's next for \"madden nfl 14\" or beyond, he said. \"i don't even want to guess,\" favre said. \"just when you think you've seen it all, something else comes out. i think that as great as it is now, the advancements that have been made; i just think it's going to grow tremendously.\" while favre is from the original generation of arcade gamers, today's nfl players have grown up with controllers in their hands. \"they play video games all the time,\" said hall of famer jerry rice, who was also on the field with favre. \"they play madden more than they\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "for i in corpus_train[4]:\n",
    "    s = table[int(i)]\n",
    "    text = text + s\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
